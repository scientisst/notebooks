{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["### Introdu\u00e7\u00e3o \u00e0 Engenharia Biom\u00e9dica (P4 - 2021/2022)\n", "# Aula Pr\u00e1tica #6 - Classifica\u00e7\u00e3o"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# <span style='color:#484848;'> Introduction to Classification </span>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### <span style='color:#00aba1;'> Keywords </span>\n", "\n", "`Classification`, `ML`, `Scikit Learn`, `HRV`"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### <span style='color:#00aba1;'> Notebook Info </span>\n", "\n", "**Contributor(s):** Rafael Silva, Hugo Pl\u00e1cido da Silva and Ana Fred\n", "\n", "**Date of creation:** 18/06/2022\n", "\n", "**Last update:** 18/06/2022"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# I. Introduction\n", "<br>\n", "<div class=\"title\"style=\"width:100%; background:linear-gradient(to right,#FDC86E,#fbb144);font-family:'arial black',monospace; text-align: center; padding: 7px 0; border-radius: 5px 50px;margin-top:-15px\" >  </div>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# <div style=\"color:#fbb144\"> 1. Background </div>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Biosignals are a rich source of information regarding a subject's characteristics and physiological states and have a multitude of applications. For instance, biosignals can be used for:\n", "* Disease diagnosis (e.g., atrial fibrillation, sleep apnea, epilepsy)\n", "* Activity monitoring (e.g., sports, fitness, driving)\n", "* Security (e.g., biometric authentication and identification)\n", "* Prognosis (e.g., epilepsy, emotions, health status)\n", "\n", "To be able to automatically perform such tasks, computational algorithms need to be developed. In this class, we will cover the main principles around classification in Machine Learning using HRV features extracted from ECG recordings to detect Atrial Fibrillation."]}, {"cell_type": "markdown", "metadata": {}, "source": ["# <div style=\"color:#fbb144\"> 2. Objectives</div>\n", "* Understand what is a binary classification problem and why it is important in physiological computing\n", "* Get acquainted with the basics of the Scikit Learn library for Python\n", "* Learn how to evaluate model performance based on simple classification metrics"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# II. Classification in Machine Learning\n", "<br>\n", "<div style=\"width:100%; background:linear-gradient(to right,#FDC86E,#fbb144);font-family:'arial black'; text-align: center; padding: 7px 0; border-radius: 5px 50px; margin-top:-15px\" > </div>\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# <div style=\"color:#fbb144\"> 1. Project Pipeline </div>\n", "\n", "<img src =\"_Resources/ML_pipeline.png\">\n", "\n", "#### Problem Definition\n", "- **What is the problem?** (formulation)\n", "- Why does the problem need to be solved? (motivation)\n", "- How would I solve the problem?\n", "\n", "#### Data Collection\n", "- What data sources already exist?\n", "- What privacy concerns are there?\n", "- Is the data public?\n", "- Where should we store the files?\n", "- **Is the data labelled?**\n", "\n", "#### Data Preparation\n", "- Perform Exploratory Data Analysis (EDA)\n", "- **Data preprocessing** (e.g., filtering)\n", "- Feature selection\n", "- **Feature extraction**\n", "- Dimensionality reduction\n", "- Outlier detection\n", "- Data scaling (normalization, standardization)\n", "- **Data splitting** (train and test)\n", "\n", "#### Model Training\n", "- **Choose an algorithm** (supervised, unsupervised, semi-supervised)\n", "- **Model fitting** (avoid under and overfitting)\n", "- Hyperparameter Tuning (try different model parameters)\n", "\n", "#### Performance Evaluation\n", "- **Classification metrics** (e.g., accuracy, precision, confusion matrix)\n", "- Cross-validation (test different train/test combinations)\n", "- Compare with other models (State of the Art)\n", "\n", "<a href=\"https://www.analyticsvidhya.com/blog/2021/04/steps-to-complete-a-machine-learning-project/\">Reference</a> \n", "    \n", "Some useful Python libraries for Machine Learning include:\n", "\n", "* NumPy\n", "\n", "* SciPy\n", "\n", "* **Scikit Learn**\n", "\n", "* Theano\n", "\n", "* TensorFlow\n", "\n", "* Keras\n", "\n", "* PyTorch\n", "\n", "* Pandas\n", " \n", "* Matplotlib\n", "\n", "* Seaborn\n", "\n", "<a href=\"https://www.springboard.com/blog/data-science/python-libraries-for-machine-learning/\">Reference</a>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# <div style=\"color:#fbb144\"> 2. Binary Classification Problem </div>\n", "\n", "Binary classification is a form of classification \u2014 the process of predicting categorical variables \u2014 where the output is restricted to two classes. For example, in medical diagnosis, a binary classifier for a specific disease could take in symptoms of a patient and predict whether the patient is healthy or has a disease. The possible outcomes of the diagnosis are positive (1) and negative (0).\n", "\n", "In the case of Atrial Fibrillation detection in ECG recordings, we can define the classification problem as:\n", "\n", "* **0** - Negative - ECG does not present Atrial Fibrillation *or* ECG is in Normal Sinus Rhythm (NSR)\n", "\n", "* **1** - Positive - ECG presents Atrial Fibrillation\n", "\n", "<img src=\"_Resources/nsr_vs_af.png\" style=\"width:70%\"/>\n", "\n", "Popular algorithms that can be used for binary classification include:\n", "\n", "* Logistic Regression\n", "\n", "* **k-Nearest Neighbors**\n", "\n", "* Decision Trees\n", "\n", "* Support Vector Machine\n", "\n", "* Naive Bayes\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# III. Scikit Learn - Machine Learning in Python\n", "<br>\n", "<div style=\"width:100%; background:linear-gradient(to right,#FDC86E,#fbb144);font-family:'arial black'; text-align: center; padding: 7px 0; border-radius: 5px 50px; margin-top:-15px\" > </div>\n", "\n", "<img src=\"_Resources/scikit-learn_logo.png\" style=\"width:30%\"/>\n", "\n", "Scikit-learn is an open source machine learning library that supports supervised and unsupervised learning. It also provides various tools for model fitting, data preprocessing, model selection, model evaluation, and many other utilities. This library, which is largely written in Python, is built upon NumPy, SciPy and Matplotlib.\n", "\n", "Scikit-learn can be installed using the **conda** or **pip** commmands:\n", "\n", "```python\n", "conda install scikit-learn # preferable for anaconda\n", "!pip install scikit-learn\n", "```"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# conda install scikit-learn"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's exemplify scikit-learn's usage with an implementation of the K-Nearest Neighbors algorithm:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# <div style=\"color:#fbb144\">  1. k-Nearest Neighbors (k-NN) </div>\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["To start, we will use 3 ECG recordings:\n", "\n", "* `ecg_normal.csv` (to *train* the model)\n", "\n", "* `ecg_af.csv` (to *train* the model)\n", "\n", "* `ecg_op3.csv` (to *test* the model)\n", "\n", "Since the data are labelled (we already know their class), our goal is to train a simple k-NN model and test its performance using scikit-learn.\n", "\n", "Let's first load the files, extract the features and prepare the data:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Imports\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "\n", "# Acquisition parameters\n", "fs = 1000.\n", "\n", "# Load train data\n", "ecg_normal = np.loadtxt('_Resources/ecg_normal.csv')\n", "ecg_af = np.loadtxt('_Resources/ecg_af.csv')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import biosppy as bp\n", "def hrv(ecg, fs, show=False):\n", "    \n", "    out = bp.signals.ecg.ecg(ecg, fs, show=show)\n", "    \n", "    rpeaks = out['rpeaks']/fs*1000 # convert sample indexes to ms\n", "    rri = np.diff(rpeaks) # compute RR intervals\n", "    \n", "    # Compute max of RRIs\n", "    rr_max = np.max(rri)\n", "    \n", "    # Compute RMSSD\n", "    rr_diff = np.diff(rri)\n", "    \n", "    rmssd = np.sqrt(np.mean(rr_diff**2))\n", "    \n", "    \n", "    return np.array([rmssd, rr_max])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["normal_hrv = hrv(ecg_normal, fs)\n", "print(normal_hrv)\n", "\n", "af_hrv = hrv(ecg_af, fs)\n", "print(af_hrv)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In order to train the model, we will have to organize the input data in an ordered list, where `X` stands for the list of samples, and `y` the correspondent labels:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Organize data\n", "X = np.array([normal_hrv, af_hrv]) # feature vector\n", "y = np.array([0, 1]) # data labels"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Before the model implementation let's first visualize our train data and predict the outcome of the test data:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Load test data\n", "ecg1 = np.loadtxt('_Resources/ecg_op3.csv')\n", "ecg1_hrv = hrv(ecg1, fs)\n", "\n", "# Plot\n", "plt.xlabel('RMSSD')\n", "plt.ylabel('Max(RRI)')\n", "\n", "plt.scatter(X[y==0][:,0], X[y==0][:,1], label='NSR', color='tab:blue')\n", "plt.scatter(X[y==1][:,0], X[y==1][:,1], label='AFib', color='tab:orange')\n", "\n", "plt.scatter(ecg1_hrv[0], ecg1_hrv[1], label='Test', color='gray')\n", "plt.legend()\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Using two features makes it easier to visualize. The test data is closer to the NSR data point, so we expect the k-NN algorithm to make its prediction accordingly:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.neighbors import KNeighborsClassifier\n", "\n", "# Create and fit classifier\n", "knn = KNeighborsClassifier(n_neighbors=1)\n", "knn.fit(X, y)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Organize data\n", "X_test = np.array([ecg1_hrv]) # feature vector\n", "y_test = np.array([0]) # data labels (for testing performance)\n", "\n", "# Predict\n", "y_pred = knn.predict(X_test)\n", "print(y_pred)\n", "\n", "y_test == y_pred"]}, {"cell_type": "markdown", "metadata": {}, "source": ["As we expected, the algorithm made a correct prediction. Now let's see how can we evaluate the performance of our classification algorithm:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div style=\"background:#946db2;font-family:'arial', monospace; text-align: center; padding: 10px 0; border-radius:10px; width:70%; margin:auto \" >\n", "  <span style=\"font-size:20px;position:relative;color:white; \"> Explore </span> <br>\n", "  <div style=\"background:#d0b3e6;font-size:12px\"> \n", "      To learn more about Scikit Learn funtionalities, visit <a href=\"https://scikit-learn.org/stable/\">Scikit Learn</a>.\n", "</div>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# IV. Evaluate Classification Performance\n", "<br>\n", "<div style=\"width:100%; background:linear-gradient(to right,#FDC86E,#fbb144);font-family:'arial black'; text-align: center; padding: 7px 0; border-radius: 5px 50px; margin-top:-15px\" > </div>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n", "In the case of a binary classification problem, two distinct classes separate the data: one called positive and the other called negative. \n", "\n", "After training the classifier, a confusion matrix can be used to assess the number of correct and wrong predictions of the data used for testing, as in the figure below. The True Positive (TP) and True Negative (TN) represent the number of positive and negative samples that were correctly classified, respectively. In contrast, the False Positive (FP) and False Negative (FN) represent the number of positive and negative samples wrongly classified, respectively.\n", "\n", "<img src=\"resources/confmat.png\" style=\"width:40%\"/>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# <div style=\"color:#fbb144\">  2. Classification Metrics </div>\n", "\n", "Classification metrics evaluate the performance of a specific characteristic of a classifier, and they are an essential tool to compare different classifiers with the same task. Combining the values from the confusion matrix, several metrics can be defined:\n", "\n", "\\begin{equation}\n", "\\text {Accuracy}=\\frac{\\text{TP}+\\text{TN}}{\\text{TP}+\\text{TN}+\\text{FP}+\\text{FN}}\n", "\\label{eq:acc}\n", "\\end{equation}\n", "\n", "\\begin{equation}\n", "\\text { Precision }=\\frac{\\text { TP }}{\\text { TP }+\\text { FP }}\n", "\\label{eq:prec}\n", "\\end{equation}\n", "\n", "\\begin{equation}\n", "\\text { Recall }=\\frac{\\text { TP }}{\\text { TP }+\\text { FN }}\n", "\\label{eq:rec}\n", "\\end{equation}\n", "\n", "\\begin{equation}\n", "\\text { Specificity }=\\frac{\\text { TN }}{\\text { TN }+\\text { FP }}\n", "\\label{eq:spec}\n", "\\end{equation}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Using the `sklearn.metrics` submodule we can easily compute the metrics we are looking for:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import confusion_matrix, accuracy_score\n", "\n", "acc = accuracy_score(y_test, y_pred)\n", "print(\"Accuracy = %3.1f%%\" % (acc*100))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Because our model was able to correctly classify all the test data we had, the accuracy is 100%. However, our model may be too simple to handle the diversity of physiological variability, and for real world applications, we should have more train and test samples."]}, {"cell_type": "markdown", "metadata": {}, "source": ["# V. Atrial Fibrillation Detection using HRV Features\n", "<br>\n", "<div style=\"width:100%; background:linear-gradient(to right,#FDC86E,#fbb144);font-family:'arial black'; text-align: center; padding: 7px 0; border-radius: 5px 50px; margin-top:-15px\" > </div>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In this part, we will be using ECG recordings of a real dataset acquired using AliveCor's KardiaMobile, available in <a href=\"https://physionet.org/content/challenge-2017/1.0.0/\">PhysioNet.org</a>, which contain 8528 single short ECG lead recordings sampled at 300 Hz.\n", "\n", "In the folder `_Resources` you will find two files:\n", "* *NSR_arrays.csv* containing 100 10-second ECG recordings in Normal Sinus Rhythm\n", "* *AFib_arrays.csv* containing 100 10-second ECG recordings in Atrial Fibrillation\n", "\n", "The recordings were extracted from the database and are already preprocessed using BioSPPy.\n", "\n", "<img src=\"_Resources/kardiamobile.png\" style=\"width:40%\"/>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Imports\n", "import numpy as np\n", "from sklearn.neighbors import KNeighborsClassifier\n", "from sklearn.model_selection import train_test_split\n", "import matplotlib.pyplot as plt\n", "\n", "\n", "# Load data\n", "NSR_arrays = np.loadtxt('_Resources/NSR_arrays.csv') \n", "AFib_arrays = np.loadtxt('_Resources/AFib_arrays.csv')\n", "fs = 300. # Hz\n", "\n", "# Compute hrv metrics\n", "NSR_hrv = []\n", "for i in NSR_arrays:\n", "    NSR_hrv.append(hrv(i, fs))\n", "\n", "AFib_hrv = []\n", "for i in AFib_arrays:\n", "    AFib_hrv.append(hrv(i, fs))\n", "\n", "\n", "\n", "# Train-test split\n", "X = np.concatenate((NSR_hrv, AFib_hrv))\n", "y = np.zeros(len(X))\n", "y[len(NSR_hrv):] = 1\n", "\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n", "\n", "# Create and fit classifier\n", "knn = KNeighborsClassifier(3)\n", "knn.fit(X_train, y_train)\n", "\n", "\n", "# Plot\n", "plt.xlabel('RMSSD')\n", "plt.ylabel('Max(RRI)')\n", "\n", "plt.scatter(X[y==0][:,0], X[y==0][:,1], label='NSR', color='tab:blue')\n", "plt.scatter(X[y==1][:,0], X[y==1][:,1], label='AFib', color='tab:orange')\n", "\n", "plt.legend()\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from functions import plot_confusion_matrix\n", "from sklearn.metrics import confusion_matrix, accuracy_score\n", "\n", "# Test data\n", "y_pred = knn.predict(X_test)\n", "\n", "# Confusion matrix\n", "conf_mat = confusion_matrix(y_test, y_pred)\n", "plot_confusion_matrix(conf_mat, ['NSR', 'AFib'])\n", "\n", "acc = accuracy_score(y_test, y_pred)\n", "print(\"Accuracy = %3.1f%%\" % (acc*100))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["* https://scikit-learn.org/stable/getting_started.html\n", "\n", "* https://machinelearningmastery.com/how-to-define-your-machine-learning-problem/\n", "\n", "* https://www.analyticsvidhya.com/blog/2021/04/steps-to-complete-a-machine-learning-project/"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<tr>\n", "<td> <img src=\"_Resources/IT.png\" alt=\"Drawing\" style=\"width:200px\"/> </td>\n", "\n", "<td> <img src=\"_Resources/IST.png\" alt=\"Drawing\"\n", "style=\"width:200px\"/> </td>\n", "</tr>"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.12"}}, "nbformat": 4, "nbformat_minor": 4}